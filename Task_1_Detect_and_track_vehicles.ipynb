{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b8e1ec8",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991521c6",
   "metadata": {},
   "source": [
    "The task one is to develop an application to detect and track moving cars from a camera recording using openCV library. \n",
    "\n",
    "Install the packages required. We install openCV for computer vision and numpy to handle arrays and matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7520a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install openCV\n",
    "!pip install opencv-python\n",
    "# install numpy\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743109f2",
   "metadata": {},
   "source": [
    "Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "600f0a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import openCV library and numpy\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c2f936",
   "metadata": {},
   "source": [
    "Create a video caputre object with the video file.\n",
    "\n",
    "**Note: Please place the video in the same directory of the Jupyter notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a592f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# capture the video\n",
    "video = cv2.VideoCapture('Traffic_Laramie_1.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210c4f18",
   "metadata": {},
   "source": [
    "The following code will process the video frames and detect and track cars that are moving on the main street. We use OpenCV's BackgroundSubtractorMOG2, A Gaussian mixture-based background/foreground segmentation algorithm used for background subtraction. Background subtraction can be done by subtracting a static frame from the current frame. But this is an inefficient method. BackgroundSubtractorMOG2 algorithm is one of the efficient methods to detect objects in real-time video.\n",
    "\n",
    "We use the follwoing steps to detect the cars in the video.\n",
    "\n",
    "1. Capture the video\n",
    "2. Read the video frames\n",
    "3. Resize the frame to half\n",
    "4. Draw the line to mark the main street\n",
    "5. Apply grey conversion (noise reduction and smoothening)\n",
    "6. Apply Gaussian blur\n",
    "7. Apply foreground mask\n",
    "8. Apply thresholding\n",
    "9. Dilation (Morphological operation to increase the object area)\n",
    "10. Extract and mark the objects using contours\n",
    "11. Show the video tracking the moving cars\n",
    "\n",
    "**The code is given below and explained in detail using line comments. Press the button 'q' to close the videos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "760ccf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code is inspired by the method discussed in analyticsvidhya.com and the lectures \n",
    "# No code is copied directly from from the given reference and it is written in my own way.\n",
    "# [reference 2, Link: https://medium.com/@ggaighernt/optical-flow-and-motion-detection-5154c6ba4419]\n",
    "\n",
    "# The create background substraction object using BackgroundSubtractorMOG2 class\n",
    "bgsub_obj = cv2.createBackgroundSubtractorMOG2(detectShadows = True)\n",
    "# Initialize a matrix of 3x3 size as the kernel for dilation\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "\n",
    "# Start an infinite loop. Press button 'q' to exit\n",
    "while True:\n",
    "    \n",
    "\n",
    "    # Read the video frames using the VideoCapture object\n",
    "    ret, frame = video.read()\n",
    "    # ret will be false if no frame is captured\n",
    "    # check if the frame is grabbed successfully\n",
    "    if not ret:\n",
    "        continue\n",
    "    \n",
    "    # Resize frame to half. It will make the frame processing by the algorithms much faster\n",
    "    frame_resized = cv2.resize(frame, (0, 0), None, 0.5, 0.5)\n",
    "    \n",
    "    # Draw a line to mark the main street\n",
    "    cv2.line(frame_resized, (0, 150),(520,150),(255, 0, 0))\n",
    "\n",
    "    # use cvtColor to convert the frame from one colour space to another\n",
    "    # Here we convert it to cv2.COLOR_BGR2GRAY colour space (grayscale)\n",
    "    # Gray conversion reduce dimensions, model complexity, make it compatible for other algorithms\n",
    "    gray_frame=cv2.cvtColor(frame_resized,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Gaussian blur: Frame is colvolved with Gaussian filter\n",
    "    # Removes Gaussian noise and high frequency components\n",
    "    blur_frame=cv2.GaussianBlur(gray_frame,(5,5),0)\n",
    "    \n",
    "    # apply the foreground mask using createBackgroundSubtractorMOG2 object's 'apply' method\n",
    "    # It will be applied on each frame\n",
    "    frame_mask = bgsub_obj.apply(blur_frame)\n",
    "    \n",
    "    # Thresholding: Each pixel values is compared to the threshold - 150\n",
    "    # If the pixel value is less than 150 it is set to 0 otherwise 255\n",
    "    threshold_frame=cv2.threshold(frame_mask,150,255, cv2.THRESH_BINARY)[1]\n",
    "    \n",
    "    # Dilation: The kernel matrix is applied to convolve the frame\n",
    "    # It increases the white region and make the object detectible\n",
    "    dilated = cv2.dilate(threshold_frame, kernel, iterations = 2)\n",
    "\n",
    "    # Contours: The findContours() method of openCV helps to find the contours in the threshold_frame\n",
    "    # It uses simple aproximation method to find the endpoints of the objects\n",
    "    (contours,_)=cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Iterate over the contours and mark the object\n",
    "    for c in contours:\n",
    "        \n",
    "        # Draw a rectangle around the object\n",
    "        (x, y, w, h)=cv2.boundingRect(c)\n",
    "        \n",
    "        # contourArea() method filters out any small contours ignore it\n",
    "        # if y value is less than 150, the object is not in the main street\n",
    "        if cv2.contourArea(c) < 1000 or y < 150:\n",
    "            continue\n",
    "            \n",
    "        # add the rectangle to the resized frame\n",
    "        cv2.rectangle(frame_resized, (x, y), (x+w, y+h), (0,255,0), 1)\n",
    "    \n",
    "    # show the resized and dilated videos\n",
    "    cv2.imshow('Video', frame_resized)\n",
    "    cv2.imshow('Dilated', dilated)\n",
    "    \n",
    "    # Press 'q' to 'quit'\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# release the video capture object and close all windows\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098b91f7",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "1. https://www.analyticsvidhya.com/blog/2022/03/vehicle-motion-detection-using-background-subtraction/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af79f943",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
